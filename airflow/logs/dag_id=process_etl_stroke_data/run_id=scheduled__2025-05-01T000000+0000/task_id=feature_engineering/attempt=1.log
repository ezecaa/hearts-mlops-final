[2025-05-02T15:13:19.735+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: process_etl_stroke_data.feature_engineering scheduled__2025-05-01T00:00:00+00:00 [queued]>
[2025-05-02T15:13:19.745+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: process_etl_stroke_data.feature_engineering scheduled__2025-05-01T00:00:00+00:00 [queued]>
[2025-05-02T15:13:19.746+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-05-02T15:13:19.760+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonVirtualenvDecoratedOperator): feature_engineering> on 2025-05-01 00:00:00+00:00
[2025-05-02T15:13:19.766+0000] {standard_task_runner.py:60} INFO - Started process 558 to run task
[2025-05-02T15:13:19.768+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'process_etl_stroke_data', 'feature_engineering', 'scheduled__2025-05-01T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/etl_processing.py', '--cfg-path', '/tmp/tmpl_jvybtn']
[2025-05-02T15:13:19.770+0000] {standard_task_runner.py:88} INFO - Job 3: Subtask feature_engineering
[2025-05-02T15:13:19.829+0000] {task_command.py:423} INFO - Running <TaskInstance: process_etl_stroke_data.feature_engineering scheduled__2025-05-01T00:00:00+00:00 [running]> on host 612cef286438
[2025-05-02T15:13:19.894+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Brain Stroke Project' AIRFLOW_CTX_DAG_ID='process_etl_stroke_data' AIRFLOW_CTX_TASK_ID='feature_engineering' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T00:00:00+00:00'
[2025-05-02T15:13:19.896+0000] {process_utils.py:182} INFO - Executing cmd: /usr/local/bin/python -m virtualenv /tmp/venvpwkndp3y --system-site-packages --python=python
[2025-05-02T15:13:19.905+0000] {process_utils.py:186} INFO - Output:
[2025-05-02T15:13:20.583+0000] {process_utils.py:190} INFO - created virtual environment CPython3.8.18.final.0-64 in 327ms
[2025-05-02T15:13:20.583+0000] {process_utils.py:190} INFO -   creator CPython3Posix(dest=/tmp/venvpwkndp3y, clear=False, no_vcs_ignore=False, global=True)
[2025-05-02T15:13:20.584+0000] {process_utils.py:190} INFO -   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/tmp/tmp_3xu_okc)
[2025-05-02T15:13:20.584+0000] {process_utils.py:190} INFO -     added seed packages: pip==23.3.1, setuptools==69.0.2, wheel==0.42.0
[2025-05-02T15:13:20.585+0000] {process_utils.py:190} INFO -   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
[2025-05-02T15:13:20.612+0000] {process_utils.py:182} INFO - Executing cmd: /tmp/venvpwkndp3y/bin/pip install -r /tmp/venvpwkndp3y/requirements.txt
[2025-05-02T15:13:20.619+0000] {process_utils.py:186} INFO - Output:
[2025-05-02T15:13:21.277+0000] {process_utils.py:190} INFO - WARNING: The directory '/home/***/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.
[2025-05-02T15:13:21.492+0000] {process_utils.py:190} INFO - Collecting awswrangler==3.9.1 (from -r /tmp/venvpwkndp3y/requirements.txt (line 1))
[2025-05-02T15:13:21.536+0000] {process_utils.py:190} INFO -   Downloading awswrangler-3.9.1-py3-none-any.whl.metadata (17 kB)
[2025-05-02T15:13:21.582+0000] {process_utils.py:190} INFO - Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (1.37.38)
[2025-05-02T15:13:21.583+0000] {process_utils.py:190} INFO - Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (1.37.38)
[2025-05-02T15:13:21.584+0000] {process_utils.py:190} INFO - Requirement already satisfied: numpy<2.0,>=1.18 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (1.24.4)
[2025-05-02T15:13:21.585+0000] {process_utils.py:190} INFO - Requirement already satisfied: packaging<25.0,>=21.1 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (23.2)
[2025-05-02T15:13:21.586+0000] {process_utils.py:190} INFO - Requirement already satisfied: pandas<2.1.0,>=1.2.0 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (2.0.3)
[2025-05-02T15:13:21.587+0000] {process_utils.py:190} INFO - Requirement already satisfied: pyarrow>=8.0.0 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (14.0.2)
[2025-05-02T15:13:21.587+0000] {process_utils.py:190} INFO - Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (4.9.0)
[2025-05-02T15:13:21.593+0000] {process_utils.py:190} INFO - Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/***/.local/lib/python3.8/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (0.10.0)
[2025-05-02T15:13:21.595+0000] {process_utils.py:190} INFO - Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/***/.local/lib/python3.8/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (0.11.5)
[2025-05-02T15:13:21.602+0000] {process_utils.py:190} INFO - Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/***/.local/lib/python3.8/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (2.8.2)
[2025-05-02T15:13:21.604+0000] {process_utils.py:190} INFO - Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/***/.local/lib/python3.8/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (1.26.18)
[2025-05-02T15:13:21.682+0000] {process_utils.py:190} INFO - Requirement already satisfied: pytz>=2020.1 in /home/***/.local/lib/python3.8/site-packages (from pandas<2.1.0,>=1.2.0->awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (2023.3.post1)
[2025-05-02T15:13:21.683+0000] {process_utils.py:190} INFO - Requirement already satisfied: tzdata>=2022.1 in /home/***/.local/lib/python3.8/site-packages (from pandas<2.1.0,>=1.2.0->awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (2023.4)
[2025-05-02T15:13:21.691+0000] {process_utils.py:190} INFO - Requirement already satisfied: six>=1.5 in /home/***/.local/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler==3.9.1->-r /tmp/venvpwkndp3y/requirements.txt (line 1)) (1.16.0)
[2025-05-02T15:13:21.725+0000] {process_utils.py:190} INFO - Downloading awswrangler-3.9.1-py3-none-any.whl (381 kB)
[2025-05-02T15:13:21.752+0000] {process_utils.py:190} INFO -    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 381.7/381.7 kB 15.6 MB/s eta 0:00:00
[2025-05-02T15:13:24.419+0000] {process_utils.py:190} INFO - Installing collected packages: awswrangler
[2025-05-02T15:13:24.662+0000] {process_utils.py:190} INFO - Successfully installed awswrangler-3.9.1
[2025-05-02T15:13:24.763+0000] {process_utils.py:190} INFO - 
[2025-05-02T15:13:24.764+0000] {process_utils.py:190} INFO - [notice] A new release of pip is available: 23.3.1 -> 25.0.1
[2025-05-02T15:13:24.764+0000] {process_utils.py:190} INFO - [notice] To update, run: python -m pip install --upgrade pip
[2025-05-02T15:13:24.967+0000] {process_utils.py:182} INFO - Executing cmd: /tmp/venvpwkndp3y/bin/python /tmp/venv-callruriet6g/script.py /tmp/venv-callruriet6g/script.in /tmp/venv-callruriet6g/script.out /tmp/venv-callruriet6g/string_args.txt /tmp/venv-callruriet6g/termination.log
[2025-05-02T15:13:24.975+0000] {process_utils.py:186} INFO - Output:
[2025-05-02T15:13:25.704+0000] {process_utils.py:190} INFO - WARNING:root:/opt/***/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2025-05-02T15:13:27.843+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:27.843+0000[0m] {[34mscript.py:[0m61} INFO[0m - Loading dataset from S3/Minio[0m
[2025-05-02T15:13:27.856+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:27.855+0000[0m] {[34mcredentials.py:[0m1213} INFO[0m - Found credentials in environment variables.[0m
[2025-05-02T15:13:27.994+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:27.993+0000[0m] {[34mconfigprovider.py:[0m998} INFO[0m - Found endpoint for s3 via: environment_service.[0m
[2025-05-02T15:13:28.066+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.065+0000[0m] {[34mscript.py:[0m69} INFO[0m - Dataset loaded successfully from s3://data/raw/stroke_data.csv[0m
[2025-05-02T15:13:28.066+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.065+0000[0m] {[34mscript.py:[0m70} INFO[0m - Dataset shape: (5110, 12)[0m
[2025-05-02T15:13:28.067+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.066+0000[0m] {[34mscript.py:[0m71} INFO[0m - Dataset columns: ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke'][0m
[2025-05-02T15:13:28.068+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.066+0000[0m] {[34mscript.py:[0m77} INFO[0m - Limpiando datos eliminando duplicados y manejando valores nulos[0m
[2025-05-02T15:13:28.072+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.071+0000[0m] {[34mscript.py:[0m84} INFO[0m - Removed 0 duplicate rows[0m
[2025-05-02T15:13:28.075+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.075+0000[0m] {[34mscript.py:[0m98} INFO[0m - No null values remaining in the dataset[0m
[2025-05-02T15:13:28.076+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.075+0000[0m] {[34mscript.py:[0m101} INFO[0m - Iniciando ingeniería de características[0m
[2025-05-02T15:13:28.076+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.075+0000[0m] {[34mscript.py:[0m55} INFO[0m - Applying One-Hot Encoding to columns: ['gender', 'ever_married', 'work_type', 'residence_type', 'smoking_status'][0m
[2025-05-02T15:13:28.081+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.081+0000[0m] {[34mscript.py:[0m108} INFO[0m - Applied one-hot encoding to categorical features[0m
[2025-05-02T15:13:28.082+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.081+0000[0m] {[34mscript.py:[0m113} INFO[0m - Removed 'id' column as it's not relevant for prediction[0m
[2025-05-02T15:13:28.083+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.083+0000[0m] {[34mscript.py:[0m122} INFO[0m - Truncated extreme values in 'age' column at 82.0[0m
[2025-05-02T15:13:28.084+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.084+0000[0m] {[34mscript.py:[0m122} INFO[0m - Truncated extreme values in 'avg_glucose_level' column at 240.7082[0m
[2025-05-02T15:13:28.087+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.085+0000[0m] {[34mscript.py:[0m122} INFO[0m - Truncated extreme values in 'bmi' column at 66.6[0m
[2025-05-02T15:13:28.088+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.085+0000[0m] {[34mscript.py:[0m124} INFO[0m - Feature engineering completed[0m
[2025-05-02T15:13:28.089+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.085+0000[0m] {[34mscript.py:[0m127} INFO[0m - Saving processed dataset to s3://data/processed/stroke_data.csv[0m
[2025-05-02T15:13:28.094+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.093+0000[0m] {[34mcredentials.py:[0m1213} INFO[0m - Found credentials in environment variables.[0m
[2025-05-02T15:13:28.147+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.147+0000[0m] {[34mconfigprovider.py:[0m998} INFO[0m - Found endpoint for s3 via: environment_service.[0m
[2025-05-02T15:13:28.184+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.184+0000[0m] {[34mscript.py:[0m131} INFO[0m - Processed dataset saved successfully to s3://data/processed/stroke_data.csv[0m
[2025-05-02T15:13:28.187+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.184+0000[0m] {[34mscript.py:[0m137} INFO[0m - Updating dataset information in S3/Minio[0m
[2025-05-02T15:13:28.193+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.192+0000[0m] {[34mcredentials.py:[0m1213} INFO[0m - Found credentials in environment variables.[0m
[2025-05-02T15:13:28.247+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.246+0000[0m] {[34mconfigprovider.py:[0m998} INFO[0m - Found endpoint for s3 via: environment_service.[0m
[2025-05-02T15:13:28.259+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.258+0000[0m] {[34mscript.py:[0m152} INFO[0m - No existing dataset information found, initializing new info dictionary[0m
[2025-05-02T15:13:28.267+0000] {process_utils.py:190} INFO - [[34m2025-05-02T15:13:28.267+0000[0m] {[34mscript.py:[0m167} INFO[0m - Target column for dataset: log_cnt[0m
[2025-05-02T15:13:28.273+0000] {process_utils.py:190} INFO - Traceback (most recent call last):
[2025-05-02T15:13:28.274+0000] {process_utils.py:190} INFO -   File "/tmp/venv-callruriet6g/script.py", line 229, in <module>
[2025-05-02T15:13:28.274+0000] {process_utils.py:190} INFO -     res = feature_engineering(*arg_dict["args"], **arg_dict["kwargs"])
[2025-05-02T15:13:28.275+0000] {process_utils.py:190} INFO -   File "/tmp/venv-callruriet6g/script.py", line 170, in feature_engineering
[2025-05-02T15:13:28.275+0000] {process_utils.py:190} INFO -     dataset_log = df.drop(columns=target_col)
[2025-05-02T15:13:28.276+0000] {process_utils.py:190} INFO -   File "/home/***/.local/lib/python3.8/site-packages/pandas/core/frame.py", line 5258, in drop
[2025-05-02T15:13:28.277+0000] {process_utils.py:190} INFO -     return super().drop(
[2025-05-02T15:13:28.277+0000] {process_utils.py:190} INFO -   File "/home/***/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 4549, in drop
[2025-05-02T15:13:28.278+0000] {process_utils.py:190} INFO -     obj = obj._drop_axis(labels, axis, level=level, errors=errors)
[2025-05-02T15:13:28.278+0000] {process_utils.py:190} INFO -   File "/home/***/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 4591, in _drop_axis
[2025-05-02T15:13:28.279+0000] {process_utils.py:190} INFO -     new_axis = axis.drop(labels, errors=errors)
[2025-05-02T15:13:28.280+0000] {process_utils.py:190} INFO -   File "/home/***/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py", line 6699, in drop
[2025-05-02T15:13:28.280+0000] {process_utils.py:190} INFO -     raise KeyError(f"{list(labels[mask])} not found in axis")
[2025-05-02T15:13:28.281+0000] {process_utils.py:190} INFO - KeyError: "['log_cnt'] not found in axis"
[2025-05-02T15:13:28.743+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 400, in execute
    return super().execute(context=serializable_context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 716, in execute_callable
    result = self._execute_python_callable_in_subprocess(python_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 471, in _execute_python_callable_in_subprocess
    raise AirflowException(error_msg) from None
airflow.exceptions.AirflowException: Process returned non-zero exit status 1.
"['log_cnt'] not found in axis"
[2025-05-02T15:13:28.747+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=process_etl_stroke_data, task_id=feature_engineering, execution_date=20250501T000000, start_date=20250502T151319, end_date=20250502T151328
[2025-05-02T15:13:28.759+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 3 for task feature_engineering (Process returned non-zero exit status 1.
"['log_cnt'] not found in axis"; 558)
[2025-05-02T15:13:28.768+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-05-02T15:13:28.793+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-02T15:59:53.700+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: process_etl_stroke_data.feature_engineering scheduled__2025-05-01T00:00:00+00:00 [queued]>
[2025-05-02T15:59:53.706+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: process_etl_stroke_data.feature_engineering scheduled__2025-05-01T00:00:00+00:00 [queued]>
[2025-05-02T15:59:53.706+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-05-02T15:59:53.715+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonVirtualenvDecoratedOperator): feature_engineering> on 2025-05-01 00:00:00+00:00
[2025-05-02T15:59:53.718+0000] {standard_task_runner.py:60} INFO - Started process 589 to run task
[2025-05-02T15:59:53.721+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'process_etl_stroke_data', 'feature_engineering', 'scheduled__2025-05-01T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/etl_processing.py', '--cfg-path', '/tmp/tmpbbuvv51m']
[2025-05-02T15:59:53.722+0000] {standard_task_runner.py:88} INFO - Job 3: Subtask feature_engineering
[2025-05-02T15:59:53.760+0000] {task_command.py:423} INFO - Running <TaskInstance: process_etl_stroke_data.feature_engineering scheduled__2025-05-01T00:00:00+00:00 [running]> on host 936bf26779ff
[2025-05-02T15:59:53.828+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Brain Stroke Project' AIRFLOW_CTX_DAG_ID='process_etl_stroke_data' AIRFLOW_CTX_TASK_ID='feature_engineering' AIRFLOW_CTX_EXECUTION_DATE='2025-05-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-01T00:00:00+00:00'
[2025-05-02T15:59:53.830+0000] {process_utils.py:182} INFO - Executing cmd: /usr/local/bin/python -m virtualenv /tmp/venvqlilvnhh --system-site-packages --python=python
[2025-05-02T15:59:53.839+0000] {process_utils.py:186} INFO - Output:
[2025-05-02T15:59:54.414+0000] {process_utils.py:190} INFO - created virtual environment CPython3.8.18.final.0-64 in 310ms
[2025-05-02T15:59:54.414+0000] {process_utils.py:190} INFO -   creator CPython3Posix(dest=/tmp/venvqlilvnhh, clear=False, no_vcs_ignore=False, global=True)
[2025-05-02T15:59:54.415+0000] {process_utils.py:190} INFO -   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/tmp/tmp9kvkxhbf)
[2025-05-02T15:59:54.415+0000] {process_utils.py:190} INFO -     added seed packages: pip==23.3.1, setuptools==69.0.2, wheel==0.42.0
[2025-05-02T15:59:54.416+0000] {process_utils.py:190} INFO -   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
[2025-05-02T15:59:54.445+0000] {process_utils.py:182} INFO - Executing cmd: /tmp/venvqlilvnhh/bin/pip install -r /tmp/venvqlilvnhh/requirements.txt
[2025-05-02T15:59:54.451+0000] {process_utils.py:186} INFO - Output:
[2025-05-02T15:59:55.074+0000] {process_utils.py:190} INFO - WARNING: The directory '/home/***/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.
[2025-05-02T15:59:55.271+0000] {process_utils.py:190} INFO - Collecting awswrangler==3.9.1 (from -r /tmp/venvqlilvnhh/requirements.txt (line 1))
[2025-05-02T15:59:55.319+0000] {process_utils.py:190} INFO -   Downloading awswrangler-3.9.1-py3-none-any.whl.metadata (17 kB)
[2025-05-02T15:59:55.356+0000] {process_utils.py:190} INFO - Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (1.37.38)
[2025-05-02T15:59:55.357+0000] {process_utils.py:190} INFO - Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (1.37.38)
[2025-05-02T15:59:55.358+0000] {process_utils.py:190} INFO - Requirement already satisfied: numpy<2.0,>=1.18 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (1.24.4)
[2025-05-02T15:59:55.359+0000] {process_utils.py:190} INFO - Requirement already satisfied: packaging<25.0,>=21.1 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (23.2)
[2025-05-02T15:59:55.359+0000] {process_utils.py:190} INFO - Requirement already satisfied: pandas<2.1.0,>=1.2.0 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (2.0.3)
[2025-05-02T15:59:55.360+0000] {process_utils.py:190} INFO - Requirement already satisfied: pyarrow>=8.0.0 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (14.0.2)
[2025-05-02T15:59:55.361+0000] {process_utils.py:190} INFO - Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /home/***/.local/lib/python3.8/site-packages (from awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (4.9.0)
[2025-05-02T15:59:55.364+0000] {process_utils.py:190} INFO - Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/***/.local/lib/python3.8/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (0.10.0)
[2025-05-02T15:59:55.365+0000] {process_utils.py:190} INFO - Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/***/.local/lib/python3.8/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (0.11.5)
[2025-05-02T15:59:55.370+0000] {process_utils.py:190} INFO - Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/***/.local/lib/python3.8/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (2.8.2)
[2025-05-02T15:59:55.372+0000] {process_utils.py:190} INFO - Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/***/.local/lib/python3.8/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (1.26.18)
[2025-05-02T15:59:55.432+0000] {process_utils.py:190} INFO - Requirement already satisfied: pytz>=2020.1 in /home/***/.local/lib/python3.8/site-packages (from pandas<2.1.0,>=1.2.0->awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (2023.3.post1)
[2025-05-02T15:59:55.433+0000] {process_utils.py:190} INFO - Requirement already satisfied: tzdata>=2022.1 in /home/***/.local/lib/python3.8/site-packages (from pandas<2.1.0,>=1.2.0->awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (2023.4)
[2025-05-02T15:59:55.439+0000] {process_utils.py:190} INFO - Requirement already satisfied: six>=1.5 in /home/***/.local/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler==3.9.1->-r /tmp/venvqlilvnhh/requirements.txt (line 1)) (1.16.0)
[2025-05-02T15:59:55.473+0000] {process_utils.py:190} INFO - Downloading awswrangler-3.9.1-py3-none-any.whl (381 kB)
[2025-05-02T15:59:55.494+0000] {process_utils.py:190} INFO -    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 381.7/381.7 kB 21.0 MB/s eta 0:00:00
[2025-05-02T15:59:57.619+0000] {process_utils.py:190} INFO - Installing collected packages: awswrangler
[2025-05-02T15:59:57.804+0000] {process_utils.py:190} INFO - Successfully installed awswrangler-3.9.1
[2025-05-02T15:59:57.886+0000] {process_utils.py:190} INFO - 
[2025-05-02T15:59:57.887+0000] {process_utils.py:190} INFO - [notice] A new release of pip is available: 23.3.1 -> 25.0.1
[2025-05-02T15:59:57.887+0000] {process_utils.py:190} INFO - [notice] To update, run: python -m pip install --upgrade pip
[2025-05-02T15:59:58.011+0000] {process_utils.py:182} INFO - Executing cmd: /tmp/venvqlilvnhh/bin/python /tmp/venv-callnygzw0js/script.py /tmp/venv-callnygzw0js/script.in /tmp/venv-callnygzw0js/script.out /tmp/venv-callnygzw0js/string_args.txt /tmp/venv-callnygzw0js/termination.log
[2025-05-02T15:59:58.017+0000] {process_utils.py:186} INFO - Output:
[2025-05-02T15:59:58.555+0000] {process_utils.py:190} INFO - WARNING:root:/opt/***/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2025-05-02T16:00:00.103+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.102+0000[0m] {[34mscript.py:[0m61} INFO[0m - Loading dataset from S3/Minio[0m
[2025-05-02T16:00:00.115+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.114+0000[0m] {[34mcredentials.py:[0m1213} INFO[0m - Found credentials in environment variables.[0m
[2025-05-02T16:00:00.233+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.233+0000[0m] {[34mconfigprovider.py:[0m998} INFO[0m - Found endpoint for s3 via: environment_service.[0m
[2025-05-02T16:00:00.298+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.298+0000[0m] {[34mscript.py:[0m69} INFO[0m - Dataset loaded successfully from s3://data/raw/stroke_data.csv[0m
[2025-05-02T16:00:00.299+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.298+0000[0m] {[34mscript.py:[0m70} INFO[0m - Dataset shape: (5110, 12)[0m
[2025-05-02T16:00:00.299+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.298+0000[0m] {[34mscript.py:[0m71} INFO[0m - Dataset columns: ['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'residence_type', 'avg_glucose_level', 'bmi', 'smoking_status', 'stroke'][0m
[2025-05-02T16:00:00.300+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.298+0000[0m] {[34mscript.py:[0m77} INFO[0m - Limpiando datos eliminando duplicados y manejando valores nulos[0m
[2025-05-02T16:00:00.304+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.303+0000[0m] {[34mscript.py:[0m84} INFO[0m - Removed 0 duplicate rows[0m
[2025-05-02T16:00:00.307+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.307+0000[0m] {[34mscript.py:[0m98} INFO[0m - No null values remaining in the dataset[0m
[2025-05-02T16:00:00.308+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.307+0000[0m] {[34mscript.py:[0m101} INFO[0m - Iniciando ingeniería de características[0m
[2025-05-02T16:00:00.309+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.307+0000[0m] {[34mscript.py:[0m55} INFO[0m - Applying One-Hot Encoding to columns: ['gender', 'ever_married', 'work_type', 'residence_type', 'smoking_status'][0m
[2025-05-02T16:00:00.313+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.313+0000[0m] {[34mscript.py:[0m108} INFO[0m - Applied one-hot encoding to categorical features[0m
[2025-05-02T16:00:00.314+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.313+0000[0m] {[34mscript.py:[0m113} INFO[0m - Removed 'id' column as it's not relevant for prediction[0m
[2025-05-02T16:00:00.315+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.315+0000[0m] {[34mscript.py:[0m122} INFO[0m - Truncated extreme values in 'age' column at 82.0[0m
[2025-05-02T16:00:00.316+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.316+0000[0m] {[34mscript.py:[0m122} INFO[0m - Truncated extreme values in 'avg_glucose_level' column at 240.7082[0m
[2025-05-02T16:00:00.317+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.317+0000[0m] {[34mscript.py:[0m122} INFO[0m - Truncated extreme values in 'bmi' column at 66.6[0m
[2025-05-02T16:00:00.318+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.317+0000[0m] {[34mscript.py:[0m124} INFO[0m - Feature engineering completed[0m
[2025-05-02T16:00:00.318+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.317+0000[0m] {[34mscript.py:[0m127} INFO[0m - Saving processed dataset to s3://data/processed/stroke_data.csv[0m
[2025-05-02T16:00:00.326+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.325+0000[0m] {[34mcredentials.py:[0m1213} INFO[0m - Found credentials in environment variables.[0m
[2025-05-02T16:00:00.377+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.377+0000[0m] {[34mconfigprovider.py:[0m998} INFO[0m - Found endpoint for s3 via: environment_service.[0m
[2025-05-02T16:00:00.415+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.414+0000[0m] {[34mscript.py:[0m131} INFO[0m - Processed dataset saved successfully to s3://data/processed/stroke_data.csv[0m
[2025-05-02T16:00:00.415+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.414+0000[0m] {[34mscript.py:[0m137} INFO[0m - Updating dataset information in S3/Minio[0m
[2025-05-02T16:00:00.422+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.422+0000[0m] {[34mcredentials.py:[0m1213} INFO[0m - Found credentials in environment variables.[0m
[2025-05-02T16:00:00.482+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.481+0000[0m] {[34mconfigprovider.py:[0m998} INFO[0m - Found endpoint for s3 via: environment_service.[0m
[2025-05-02T16:00:00.493+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.492+0000[0m] {[34mscript.py:[0m152} INFO[0m - No existing dataset information found, initializing new info dictionary[0m
[2025-05-02T16:00:00.497+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.497+0000[0m] {[34mscript.py:[0m167} INFO[0m - Target column for dataset: log_cnt[0m
[2025-05-02T16:00:00.498+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.497+0000[0m] {[34mscript.py:[0m171} ERROR[0m - Target column 'log_cnt' not found in DataFrame. Available columns: ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke', 'gender_Male', 'gender_Other', 'ever_married_Yes', 'work_type_Never_worked', 'work_type_Private', 'work_type_Self-employed', 'work_type_children', 'residence_type_Urban', 'smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes'][0m
[2025-05-02T16:00:00.501+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.501+0000[0m] {[34mvariable.py:[0m245} WARNING[0m - The variable target_col is defined in the LocalFilesystemBackend secrets backend, which takes precedence over reading from the database. The value in the database will be updated, but to read it you have to delete the conflicting variable from LocalFilesystemBackend[0m
[2025-05-02T16:00:00.868+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.868+0000[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2025-05-02T16:00:00.872+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.871+0000[0m] {[34mscript.py:[0m175} INFO[0m - Setting target column to default value: stroke[0m
[2025-05-02T16:00:00.881+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.880+0000[0m] {[34mscript.py:[0m205} INFO[0m - Dataset information updated successfully in S3/Minio[0m
[2025-05-02T16:00:00.882+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:00.881+0000[0m] {[34mscript.py:[0m211} INFO[0m - Logging data to MLflow[0m
[2025-05-02T16:00:01.044+0000] {process_utils.py:190} INFO - 2025/05/02 16:00:01 INFO mlflow.tracking.fluent: Experiment with name 'Stroke Prediction' does not exist. Creating a new experiment.
[2025-05-02T16:00:02.550+0000] {process_utils.py:190} INFO - 2025/05/02 16:00:02 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..
[2025-05-02T16:00:02.553+0000] {process_utils.py:190} INFO - 2025/05/02 16:00:02 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.
[2025-05-02T16:00:02.584+0000] {process_utils.py:190} INFO - /home/***/.local/lib/python3.8/site-packages/mlflow/data/dataset_source_registry.py:149 UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'local file: healthcare-dataset-stroke-data.csv'. Exception:
[2025-05-02T16:00:02.585+0000] {process_utils.py:190} INFO - /home/***/.local/lib/python3.8/site-packages/mlflow/data/dataset_source_registry.py:149 UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.
[2025-05-02T16:00:02.628+0000] {process_utils.py:190} INFO - /home/***/.local/lib/python3.8/site-packages/mlflow/types/utils.py:407 UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.
[2025-05-02T16:00:02.662+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:02.662+0000[0m] {[34mscript.py:[0m235} INFO[0m - Dataset logged to MLflow successfully[0m
[2025-05-02T16:00:02.697+0000] {process_utils.py:190} INFO - 2025/05/02 16:00:02 INFO mlflow.tracking._tracking_service.client: 🏃 View run ETL_run_2025/05/02-16:00:02 at: http://mlflow:5000/#/experiments/1/runs/f759ef3f16ed40129d03540bbf98d5dd.
[2025-05-02T16:00:02.698+0000] {process_utils.py:190} INFO - 2025/05/02 16:00:02 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow:5000/#/experiments/1.
[2025-05-02T16:00:02.721+0000] {process_utils.py:190} INFO - 2025/05/02 16:00:02 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...
[2025-05-02T16:00:03.427+0000] {process_utils.py:190} INFO - 2025/05/02 16:00:03 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!
[2025-05-02T16:00:03.427+0000] {process_utils.py:190} INFO - [[34m2025-05-02T16:00:03.426+0000[0m] {[34mscript.py:[0m239} INFO[0m - MLflow run ended[0m
[2025-05-02T16:00:03.840+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-05-02T16:00:03.850+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=process_etl_stroke_data, task_id=feature_engineering, execution_date=20250501T000000, start_date=20250502T155953, end_date=20250502T160003
[2025-05-02T16:00:03.900+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-05-02T16:00:03.921+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
